{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('freshness.n.03') an alert and refreshed state\n",
      "Synset('luminescence.n.02') light from nonthermal sources\n",
      "Synset('incandescence.n.01') the phenomenon of light emission by a body as its temperature is raised\n",
      "Synset('glow.n.04') a feeling of considerable warmth\n",
      "Synset('glow.n.05') a steady even light without flames\n",
      "Synset('radiance.n.01') the amount of electromagnetic radiation leaving or arriving at a point on a surface\n",
      "Synset('gleam.n.01') an appearance of reflected light\n",
      "Synset('glow.v.01') emit a steady even light without flames\n",
      "Synset('glow.v.02') have a complexion with a strong bright color, such as red or pink\n",
      "Synset('burn.v.02') shine intensely, as if with heat\n",
      "Synset('glow.v.04') be exuberant or high-spirited\n",
      "Synset('glow.v.05') experience a feeling of well-being or happiness, as from good health or an intense emotion\n"
     ]
    }
   ],
   "source": [
    "#1) Найти все значения (синсеты) для лексемы glow\n",
    "\n",
    "glow = wordnet.synsets('glow')\n",
    "for ss in glow:\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('freshness.n.03') an alert and refreshed state\n",
      "Synset('luminescence.n.02') light from nonthermal sources\n"
     ]
    }
   ],
   "source": [
    "#2) Найти определение для лексемы glow в значении (а) \"бодрость\" и в значении (b) \"нетепловой свет\"\n",
    "\n",
    "print(glow[0], glow[0].definition())\n",
    "print(glow[1], glow[1].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'finally', 'understand', 'why', 'people', 'say', 'pregnant', 'women', 'glow']\n",
      "['Since', 'the', 'TPM', 'operates', 'according', 'to', 'the', 'Diesel', 'cycle', 'the', 'spark', 'plug', '56', 'may', 'be', 'eliminated', 'or', 'may', 'be', 'replaced', 'by', 'a', 'glow', 'plug']\n"
     ]
    }
   ],
   "source": [
    "#3) Найдите два произвольных контекста для слова plant в значениях (a) \"бодрость\" и (b) \"искусственный свет\"; \n",
    "#продемонстрируйте на них действие алгоритма Леска для разрешения неоднозначности\n",
    "\n",
    "sent1 = 'I finally understand why people say pregnant women glow.'\n",
    "sent2 = 'A glow suffused, then focused down into a flashlight. Vigor climbed to within a half-dozen stairs. He waved to her.'\n",
    "sent1_tokens = [word.strip('.,') for word in sent1.split(' ')]\n",
    "sent2_tokens = [word.strip('.,') for word in sent2.split(' ')]\n",
    "print(sent1_tokens)\n",
    "print(sent2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the amount of electromagnetic radiation leaving or arriving at a point on a surface\n",
      "the amount of electromagnetic radiation leaving or arriving at a point on a surface\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "print(lesk(sent1_tokens, 'glow').definition())\n",
    "print(lesk(sent2_tokens, 'glow').definition())\n",
    "\n",
    "#Алгоритм Леска не помог разрешить мнеоднозначность, более того, \n",
    "#он даже не выявил, что она там естьindustry = wordnet.synsets('industry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('good_health.n.01') the state of being vigorous and free from bodily or mental disease\n",
      "Synset('luminosity.n.01') the quality of being luminous; emitting or reflecting light\n"
     ]
    }
   ],
   "source": [
    "#4) Найдите гиперонимы для значения (a) и гиперонимы для значения (b)\n",
    "\n",
    "for ss in glow[0].hypernyms():\n",
    "    print(ss, ss.definition())\n",
    "for ss in glow[1].hypernyms():\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min d(glow: \"бодрость\", freshness): 0\n",
      "closest lemma definition: an alert and refreshed state\n",
      "\n",
      "min d(glow: \"бодрость\", luminescence): 9\n",
      "closest lemma definition: light from nonthermal sources\n",
      "\n",
      "min d(glow: \"искусственный свет\", freshness): 6\n",
      "closest lemma definition: the property of being pure and fresh (as if newly made); not stale or deteriorated\n",
      "\n",
      "min d(glow: \"искусственный свет\", luminescence): 0\n",
      "closest lemma definition: light from nonthermal sources\n",
      "\n",
      "min (d(glow: \"бодрость\", freshness), d(glow: \"бодрость\", luminescence)): 0\n",
      "min (d(glow: \"искусственный свет\", freshness), d(glow: \"искусственный свет\", luminescence)): 0\n"
     ]
    }
   ],
   "source": [
    "#5) Вычислите наименьшее расстояние между значением glow \"бодрость\" и значениями лексемы freshness, \n",
    "#а также glow \"искусственный свет\" и значениями лексемы luminescence\n",
    "#Найти min (d(glow: \"бодрость\", freshness), d(glow: \"бодрость\", luminescence)), \n",
    "#а также min (d(glow: \"искусственный свет\", freshness), d(glow: \"искусственный свет\", luminescence))\n",
    "freshness = wordnet.synsets('freshness')\n",
    "luminescence = wordnet.synsets('luminescence')\n",
    "\n",
    "def get_dist_sim(ss1, lexeme):\n",
    "    distances = []\n",
    "    similarities = []\n",
    "    for ss2 in lexeme:\n",
    "        dist = ss1.shortest_path_distance(ss2)\n",
    "        if dist is not None:\n",
    "            distances.append(dist)\n",
    "            sim = ss1.path_similarity(ss2)\n",
    "            similarities.append(sim)\n",
    "    return distances, similarities\n",
    "\n",
    "# min d(glow: \"бодрость\", freshness)\n",
    "dist1 = get_dist_sim(glow[0], freshness)[0]\n",
    "print('min d(glow: \"бодрость\", freshness): {}'.format(min(dist1)))\n",
    "print('closest lemma definition: {}\\n'.format(freshness[dist1.index(min(dist1))].definition()))\n",
    "# Правда, здесь выводится только одно ближайшее значение. Их может быть несколько.\n",
    "\n",
    "# min d(glow: \"бодрость\", luminescence)\n",
    "dist2 = get_dist_sim(glow[0], luminescence)[0]\n",
    "print('min d(glow: \"бодрость\", luminescence): {}'.format(min(dist2)))\n",
    "print('closest lemma definition: {}\\n'.format(luminescence[dist2.index(min(dist2))].definition()))\n",
    "\n",
    "# min d(glow: \"искусственный свет\", freshness)\n",
    "dist3 = get_dist_sim(glow[1], freshness)[0]\n",
    "print('min d(glow: \"искусственный свет\", freshness): {}'.format(min(dist3)))\n",
    "print('closest lemma definition: {}\\n'.format(freshness[dist3.index(min(dist3))].definition()))\n",
    "\n",
    "# min d(glow: \"искусственный свет\", luminescence)\n",
    "dist4 = get_dist_sim(glow[1], luminescence)[0]\n",
    "print('min d(glow: \"искусственный свет\", luminescence): {}'.format(min(dist4)))\n",
    "print('closest lemma definition: {}\\n'.format(luminescence[dist4.index(min(dist4))].definition()))\n",
    "\n",
    "print('min (d(glow: \"бодрость\", freshness), d(glow: \"бодрость\", luminescence)): {}'.format(min(min(dist1), min(dist2))))\n",
    "print('min (d(glow: \"искусственный свет\", freshness), d(glow: \"искусственный свет\", luminescence)): {}'.format(min(min(dist3), min(dist4))))\n",
    "\n",
    "#как можно заметить, минимальное расстояние равно 0 для обоих слов, что означает, \n",
    "#что значение \"бодрость\" максимально близко значению слова fresheness, \n",
    "#а значение \"искусстенный свет\" максимально близко значению слова luminescence, что в общем-то не удивительно, \n",
    "#т.к. слово glow в каждом из этих значений входит в синсеты слов, минимальное расстояние до которых мы мерили"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('rattlesnake_master.n.01') coarse prickly perennial eryngo of United States thought to cure rattlesnake bite\n"
     ]
    }
   ],
   "source": [
    "#6)Вычислить двумя разными способами расстояние:\n",
    "#d(glow: \"растение\", rattlesnake's master) и d(organism, whole)\n",
    "#Есть ли разница в расстояниях? Какое из расстояний, по Вашему мнению, в лучшей степени отражает интуитивное \n",
    "#представление о семантической близости слов?\n",
    "\n",
    "master = wordnet.synsets(\"rattlesnake's_master\")\n",
    "for ss in master:\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06666666666666667\n",
      "0.9295359586241757\n"
     ]
    }
   ],
   "source": [
    "#Посчитаем близость с помощью критериев Path Similarity, Leacock-Chodorow Similarity\n",
    "\n",
    "from nltk.corpus import wordnet_ic\n",
    "ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "#Path Similarity\n",
    "print(glow[1].path_similarity(master[0]))\n",
    "\n",
    "#Leacock-Chodorow Similarity\n",
    "print(glow[1].lch_similarity(master[0]))\n",
    "\n",
    "#В данном случае, очевидно, Path Similarity лучше определяет семантическую отдаленность двух слов, \n",
    "#и, на мой взгляд, он же лучше всего отражает интуитивное представление о семантической похожести этих слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('organism.n.01') a living thing that has (or can develop) the ability to act or function independently\n",
      "Synset('organism.n.01') []\n",
      "Synset('organism.n.02') a system considered analogous in structure or function to a living body\n",
      "Synset('organism.n.02') ['the social organism']\n"
     ]
    }
   ],
   "source": [
    "organism = wordnet.synsets('organism')\n",
    "for ss in organism:\n",
    "    print(ss, ss.definition())\n",
    "    print(ss, ss.examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('whole.n.01') all of something including all its component elements or parts\n",
      "Synset('whole.n.01') ['Europe considered as a whole', 'the whole of American literature']\n",
      "Synset('whole.n.02') an assemblage of parts that is regarded as a single entity\n",
      "Synset('whole.n.02') ['how big is that part compared to the whole?', 'the team is a unit']\n"
     ]
    }
   ],
   "source": [
    "whole = wordnet.synsets('whole', 'n')\n",
    "for ss in whole:\n",
    "    print(ss, ss.definition())\n",
    "    print(ss, ss.examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a living thing that has (or can develop) the ability to act or function independently\n",
      "all of something including all its component elements or parts\n",
      "0.07692307692307693\n",
      "1.072636802264849\n",
      "a living thing that has (or can develop) the ability to act or function independently\n",
      "an assemblage of parts that is regarded as a single entity\n",
      "0.3333333333333333\n",
      "2.538973871058276\n",
      "a system considered analogous in structure or function to a living body\n",
      "all of something including all its component elements or parts\n",
      "0.1\n",
      "1.3350010667323402\n",
      "a system considered analogous in structure or function to a living body\n",
      "an assemblage of parts that is regarded as a single entity\n",
      "0.125\n",
      "1.55814461804655\n"
     ]
    }
   ],
   "source": [
    "for ss1 in organism:\n",
    "    for ss2 in whole:\n",
    "        print(ss1.definition())\n",
    "        print(ss2.definition())\n",
    "        \n",
    "        #Path Similarity\n",
    "        print(ss1.path_similarity(ss2))\n",
    "\n",
    "        #Leacock-Chodorow Similarity\n",
    "        print(ss1.lch_similarity(ss2))\n",
    "        \n",
    "#В данном случае, т.к. ни по одному из синсетов (да и интуитивно тоже) слова не похожи, критерий\n",
    "#с меньшей оценкой будет лучше отражать интуитивное представление, поэтому Path Similarity\n",
    "#оказывается лучше как для первой пары слов (glow: \"растение\", rattlesnake's master), \n",
    "#так и для второй (organism, whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
